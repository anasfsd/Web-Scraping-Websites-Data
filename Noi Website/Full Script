from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
import time

# Set up the Chrome driver
service = Service(executable_path='D:/chromedriver.exe')  # Ensure the path is correct
options = webdriver.ChromeOptions()
driver = webdriver.Chrome(service=service, options=options)

try:
    # Open the input and output files
    with open(r"C:\Users\Hassan Laptop Point\Downloads\noi22.txt", "r", encoding="utf-8") as file:
        with open(r"C:\Users\Hassan Laptop Point\Downloads\noi3.txt", "w", encoding="utf-8") as file_write:
            lines = file.readlines()  # Read all lines from the input file

            for line in lines:
                url = line.strip().split("####")[0]  # Extract the URL
                driver.get(url)  # Open the URL in the browser
                time.sleep(3)  # Wait for the page to load

                # Get page source and parse with BeautifulSoup
                content = driver.page_source
                soup = BeautifulSoup(content, "html.parser")

                # Extract title
                try:
                    title_tag = soup.find('div', class_='ut2-pb__title ut2-pb__title-wrap').find('h1')
                    title = title_tag.text.strip().replace('\n', '') if title_tag else ''
                except Exception as e:
                    title = ''
                    print(f"Error extracting title: {e}")

                try:
                    # Find the span containing the product code
                    product_code_span = soup.find("span", id=lambda x: x and x.startswith("product_code_"))

                    if product_code_span:
                        product_code = product_code_span.text.strip()
                except Exception as e:
                    ''

                # Extract description
                try:
                    des_tag = soup.find('div', class_='ty-wysiwyg-content ab-mb-style-presets')
                    des_tag=str(des_tag).strip().replace('\n','')
                except Exception as e:
                    des_tag = ''
                    print(f"Error extracting description: {e}")

                # Extract EAN
                try:
                    ean_tag = soup.find('div', class_='ty-product-feature')
                    eans = ean_tag.text.strip().replace('\n', '') if ean_tag else ''
                except Exception as e:
                    eans = ''
                    print(f"Error extracting EAN: {e}")
                # Initialize an empty list to store image URLs
                image_urls = []

                # Find the main image wrapper
                image_wrapper = soup.find("div", class_="ut2-pb__img-wrapper")

                # Extract all unique image sources inside the wrapper
                if image_wrapper:
                    images = image_wrapper.find_all("img")

                    # Use a set to store unique image URLs
                    unique_image_urls = set(img["src"] for img in images if "src" in img.attrs)

                    # Convert the set back to a list and extend image_urls
                    image_urls.extend(unique_image_urls)

                    # Print extracted unique image URLs
                    for img_url in unique_image_urls:
                        print(image_urls)
                else:
                    print("No image wrapper found.")

                # Write extracted data to file
                file_write.write(f"{title}####{product_code}####{des_tag}####{eans}####{image_urls}####{line}")
                print(title)
                print(product_code)
                print(des_tag)
                print(eans)

finally:
    driver.quit()
